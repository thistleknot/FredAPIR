install.packages("zoo")
install.packages("xts")
install.packages("tidyquant")

#note
#2008 05 01 most important datasets start here

start_date="2008-05-01"

library(data.table)
library(zoo)
library(xts)
library(tidyquant)

semanticList = c("Population", "Price", "Employment","Consumer", "500", "Monetary Base", "Real", "Money Stock", "Treasury",  "Spread")

semanticScore=77

semantic<-c()

parsedList<-c()

names<-c()
popularityScores<-c()

x=1
for (i in semanticList)
{
  y=1
  count=1

  #load up data
  semantic<-fred$series.search(semanticList[x])

  #loop through popularity scores
  #print(semanticList[x])
  for (y in semantic$popularity)
  {
    #if specific score is greater than 77, capture

    #as.numeric(as.character(semantic$popularity[count]))

    #https://stackoverflow.com/questions/2288485/how-to-convert-a-data-frame-column-to-numeric-type
    #if((semantic$popularity[count])>77)
    if((as.numeric(as.character(semantic$popularity[count])))>semanticScore)
    {
      {
        #print("above")
        #print(semantic$id[count])

        #print(semantic$popularity[count])

        names<-c(names,semantic$id[count])
        popularityScores<-c(popularityScores,semantic$popularity[count])

      }

    }
    else
    {

    }

    count=count+1
  }

  x=x+1

}

parsedList<-unique(names)

print(parsedList)

#https://stackoverflow.com/questions/50118593/r-join-all-datasets-by-date/50139902#50139902
# first download all the data    
#by Gregor 2018-05-2
data_list = lapply(parsedList, function(a)
  fred$series.observations(
    series_id = a,
    observation_start = start_date,
    observation_end = "2018-03-01"
  )
)

# define function to process the data
# we plan on re-naming the "value" column so each one is distinct
process_data = function(d, value_name) {
  d = d[, c("date", "value")]
  d$date = as.Date(d$date)
  d$value = as.numeric(d$value)
  names(d)[2] = value_name
  return(d)
}

# process the data
data_list_processed = list()
for (i in seq_along(data_list)) {
  
  #apply names
  data_list_processed[[i]] = process_data(data_list[[i]], value_name = parsedList[i])

}

#merge data by date

#combined_data = Reduce(merge, data_list_processed)
combined_data = Reduce(function(x, y) merge(x, y, all = TRUE), data_list_processed)

#aggregate/reduce data from daily (due to join by date operation) to weekly
#https://stackoverflow.com/questions/10085806/extracting-specific-columns-from-a-data-frame

df3 <- c()

a=2
for (i in parsedList)
{
  df <- subset(combined_data, select = c(1, a))
  
  df2 <- df %>%
    tq_transmute(select = 2,
                 mutate_fun = apply.weekly,
                 #http://www.business-science.io/timeseries-analysis/2017/07/02/tidy-timeseries-analysis.html
                 na.rm = TRUE,
                 FUN        = mean)
  #print(df2)
  
  #1st pass has date (single dataframe includes two columns)
  if(a==2)
  {
    df3 <- df2
    a=a+1  
  }
  else
    #subsequent passes include two columns across two dataframes
  {
    df3 <- c(df3, df2[,2])
    a=a+1
  }
  
}

#https://stackoverflow.com/a/50173660/1731972
library(zoo)
#this .csv is my weekly aggregated df3
combined_data_z <- read.csv(file="http://thistleknot.sytes.net/wordpress/wp-content/uploads/2018/04/output_NoNA.csv")


test1_z_approx <- matrix(NA, ncol=ncol(combined_data_z)-2, nrow = nrow(combined_data_z))
for (i in 3:ncol(combined_data_z))
{
  
  dates <- combined_data_z[,1]
  test1 <- combined_data_z[,i]
  test1_z <- zoo(test1)
  test1_z_approx[,i-2] <-as.matrix( na.fill(na.approx(test1_z, x=dates, rule=2, na.rm = FALSE), "extend"))[,1]
  
}
#right now, list exports with incorrect headers, includes an additional row column, and no date column.  Also extends the beginning date range to beginning of year.  
#I fix all this post export.
write.csv(test1_z_approx, file = "output_test.csv")

# to to break apart data into 2 lists to run through interpolation, then to to re-integrate together per column.
# ,1 = date
# ,2 = 1st dataset, trying to get a loop using a

df4 <- c()

a=2
for (i in parsedList)
{
  #print(dates)
  
  #df <- subset(combined_data, select = c(1, a))

    #must start with 2
  #a=2
  df4 <- subset(combined_data, select = c(1, a))
  
  test1=df4[,2]
  
  dates <- c(df4[,1])
  
  
  int(test1[,1])
  print(dates[1])
  
  
  #index(dates)
  #index(test1)
  #checking against error x and index must have the same length
  if((lengths(test1)-lengths(dates))!=0)
  {
    print(lengths(test1[,1])-lengths(dates[1]))  
  }
  
  test1_z_approx <- na.fill(na.approx(test1[,1], x=dates[1], rule=2), "extend")

  #print(dates)
  
  
  
  #print(test1)
  
  #test1 <- df4[,1];
  #test1_z <- zoo(test1);
  
  a=a+1
}




test1_z_approx <- na.fill(na.approx(test1, x=dates, rule=2), "extend")
#print(test1_z_approx)

write.csv(df3, file = "output.csv")

